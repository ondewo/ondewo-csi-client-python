{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbcb7936",
   "metadata": {},
   "source": [
    "## S2T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b42d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wave\n",
    "from google.protobuf.empty_pb2 import Empty\n",
    "from ondewo.s2t import speech_to_text_pb2\n",
    "from ondewo.s2t.speech_to_text_pb2 import ListS2tPipelinesRequest\n",
    "\n",
    "from typing import Iterator\n",
    "from ondewo.s2t import speech_to_text_pb2\n",
    "from typing import Iterator\n",
    "                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c9a7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_pipeline_by_language_s2t(language):\n",
    "    \n",
    "    pipelines_ids = []\n",
    "    \n",
    "    pipelines = s2t_client.services.speech_to_text.list_s2t_pipelines(\n",
    "        request=ListS2tPipelinesRequest(languages=[language])).pipeline_configs\n",
    "    \n",
    "    for pipeline in pipelines:\n",
    "        pipelines_ids.append(pipeline)\n",
    "    \n",
    "    return pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26d87ac",
   "metadata": {},
   "source": [
    "#### Example 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e809d171",
   "metadata": {},
   "outputs": [],
   "source": [
    "def s2t_ex_1(AUDIO_FILE, language):\n",
    "    \n",
    "    # List all speech-2-text pipelines (model setups) present on the server\n",
    "    # We are going to pick the first pipeline (model setup)\n",
    "    pipelines = s2t_client.services.speech_to_text.list_s2t_pipelines(request = Empty()).pipeline_configs\n",
    "    pipeline = find_pipeline_by_language_s2t(language)[0]\n",
    "\n",
    "\n",
    "    # Read file which we want to transcribe\n",
    "    with wave.open(AUDIO_FILE) as w:\n",
    "        audio: bytes = w.readframes(w.getnframes())\n",
    "\n",
    "    # Create transcription request\n",
    "    request = speech_to_text_pb2.TranscribeFileRequest(\n",
    "        s2t_pipeline_id=pipeline.id,\n",
    "        audio_file=audio,\n",
    "        ctc_decoding=speech_to_text_pb2.CTCDecoding.BEAM_SEARCH_WITH_LM\n",
    "    )\n",
    "    # Send transcription request and get response\n",
    "    transcribe_response = s2t_client.services.speech_to_text.transcribe_file(request=request)\n",
    "    \n",
    "    return transcribe_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9f75fc",
   "metadata": {},
   "source": [
    "#### Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d567792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are going to make to send the file chunk-by-chunk to simulate a stream\n",
    "def get_streaming_audio(audio_path: str, CHUNK_SIZE) -> Iterator[bytes]:\n",
    "    with wave.open(audio_path) as w:\n",
    "        chunk: bytes = w.readframes(CHUNK_SIZE)\n",
    "        while chunk != b\"\":\n",
    "            yield chunk\n",
    "            chunk = w.readframes(CHUNK_SIZE)\n",
    "\n",
    "\n",
    "def create_streaming_request(\n",
    "        audio_stream: Iterator[bytes],\n",
    "        pipeline_id: str,\n",
    ") -> Iterator[speech_to_text_pb2.TranscribeStreamRequest]:\n",
    "    for i, chunk in enumerate(audio_stream):\n",
    "        yield speech_to_text_pb2.TranscribeStreamRequest(\n",
    "            audio_chunk=chunk,\n",
    "            s2t_pipeline_id=pipeline_id,\n",
    "            spelling_correction=False,\n",
    "            ctc_decoding=speech_to_text_pb2.CTCDecoding.GREEDY,\n",
    "            end_of_stream=False,\n",
    "        )\n",
    "    # End the stream\n",
    "    \n",
    "    \n",
    "def s2t_ex_2(AUDIO_FILE, language, CHUNK_SIZE = 8000):\n",
    "    # List all speech-2-text pipelines (model setups) present on the server\n",
    "    # We are going to pick the first pipeline (model setup)\n",
    "    pipelines = s2t_client.services.speech_to_text.list_s2t_pipelines(request = Empty()).pipeline_configs\n",
    "    pipeline = pipelines[5]\n",
    "    pipeline_id = find_pipeline_by_language_s2t(language)[0].id\n",
    "\n",
    "    # Get audio stream (iterator of audio chunks)\n",
    "    audio_stream: Iterator[bytes] = get_streaming_audio(AUDIO_FILE, CHUNK_SIZE)\n",
    "\n",
    "    # Create streaming request\n",
    "    streaming_request: Iterator[speech_to_text_pb2.TranscribeStreamRequest] = \\\n",
    "        create_streaming_request(audio_stream=audio_stream, pipeline_id=pipeline_id)\n",
    "\n",
    "    # Transcribe the stream and get back responses\n",
    "    response_gen: Iterator[speech_to_text_pb2.TranscribeStreamResponse] = \\\n",
    "        s2t_client.services.speech_to_text.transcribe_stream(streaming_request)\n",
    "        \n",
    "    return response_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed67294",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging                                                           \n",
    "import queue                                                             \n",
    "import time                                                              \n",
    "import uuid                                                              \n",
    "from abc import ABCMeta, abstractmethod                                  \n",
    "from typing import Iterator, Optional                                                                       \n",
    "from ondewo.logging.logger import logger_console                         \n",
    "from ondewo.nlu.session_pb2 import (                                     \n",
    "    InputAudioConfig,                                                    \n",
    "    QueryInput,                                                          \n",
    "    StreamingDetectIntentRequest,                                        \n",
    ")       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027fdbcd",
   "metadata": {},
   "source": [
    "#### Example 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94e12db",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHUNK: int = 8000                                                        \n",
    "MONO: int = 1                                                            \n",
    "RATE: int = 16000                                                        \n",
    "PLAYING: bool = False                                                    \n",
    "WAV_HEADER_LENGTH: int = 46                                              \n",
    "SAMPLEWIDTH: int = 2  \n",
    "\n",
    "class StreamerInInterface(metaclass=ABCMeta):                            \n",
    "    @property                                                            \n",
    "    @abstractmethod                                                      \n",
    "    def mute(self) -> bool:                                              \n",
    "        pass                                                             \n",
    "                                                                         \n",
    "    @mute.setter                                                         \n",
    "    def mute(self, value: bool) -> None:                                 \n",
    "        pass                                                             \n",
    "                                                                         \n",
    "    @abstractmethod\n",
    "    def create_s2t_request(\n",
    "        self,\n",
    "        audio_stream: Iterator[bytes],\n",
    "        pipeline_id: str,\n",
    "    ) -> Iterator[speech_to_text_pb2.TranscribeStreamRequest]:\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod                                                      \n",
    "    def close(self) -> None:                                             \n",
    "        pass                                                             \n",
    "\n",
    "class PyAudioStreamerIn(StreamerInInterface):                                                         \n",
    "    def __init__(self) -> None:                                                                       \n",
    "        import pyaudio                             \n",
    "\n",
    "        self.CHUNK: int = CHUNK                                                                       \n",
    "        self.pyaudio_object: pyaudio.PyAudio = pyaudio.PyAudio()                                               \n",
    "        self.stream: pyaudio.Stream = self.pyaudio_object.open(                                                \n",
    "            channels=1,                            \n",
    "            format=pyaudio.paInt16,                                                                   \n",
    "            rate=16000,                            \n",
    "            input=True,                            \n",
    "            frames_per_buffer=self.CHUNK,                                                             \n",
    "        )                                          \n",
    "\n",
    "    @property                                      \n",
    "    def mute(self) -> bool:                                                                           \n",
    "        return PLAYING                             \n",
    "\n",
    "    @mute.setter                                   \n",
    "    def mute(self, value: bool) -> None:                                                              \n",
    "        global PLAYING                             \n",
    "        PLAYING = value                            \n",
    "\n",
    "    def close(self) -> None:                                                                          \n",
    "        self.stream.close()                                                                           \n",
    "        self.pyaudio_object.terminate()                                                               \n",
    "\n",
    "    def create_s2t_request(\n",
    "            self,\n",
    "            audio_stream: Iterator[bytes],\n",
    "            pipeline_id: str,\n",
    "    ) -> Iterator[speech_to_text_pb2.TranscribeStreamRequest]:\n",
    "        for i, chunk in enumerate(audio_stream):\n",
    "            yield speech_to_text_pb2.TranscribeStreamRequest(\n",
    "                audio_chunk=chunk,\n",
    "                s2t_pipeline_id=pipeline_id,\n",
    "                spelling_correction=False,\n",
    "                ctc_decoding=speech_to_text_pb2.CTCDecoding.GREEDY,\n",
    "                end_of_stream=False,\n",
    "            )\n",
    "        # End the stream\n",
    "        yield speech_to_text_pb2.TranscribeStreamRequest(\n",
    "            audio_chunk=b'',\n",
    "            s2t_pipeline_id=pipeline_id,\n",
    "            spelling_correction=False,\n",
    "            ctc_decoding=speech_to_text_pb2.CTCDecoding.GREEDY,\n",
    "            end_of_stream=True,\n",
    "        )                                                 \n",
    "\n",
    "    def create_transciption_requests_from_stream(self, pipeline_id: str) -> Iterator[speech_to_text_pb2.TranscribeStreamRequest]:         \n",
    "        while True:                                \n",
    "            chunk: bytes = self.stream.read(CHUNK)                                                    \n",
    "            logging.info(f\"Sending {len(chunk)} bytes\")                                                        \n",
    "            yield speech_to_text_pb2.TranscribeStreamRequest(\n",
    "                audio_chunk=chunk,                                                                    \n",
    "                s2t_pipeline_id=pipeline_id,                                                          \n",
    "                spelling_correction=False,                                                            \n",
    "                ctc_decoding=speech_to_text_pb2.CTCDecoding.BEAM_SEARCH_WITH_LM,                               \n",
    "                end_of_stream=False,                                                                  \n",
    "            )                                      \n",
    "            time.sleep(0.1)                      \n",
    "            \n",
    "        \n",
    "                                      \n",
    "def live_speech_helper(                                                                                        \n",
    "    pipeline_id: str,                                                                            \n",
    "    session_id: str,                                                                             \n",
    "    save_to_disk: bool,                                                                          \n",
    "    streamer_name: str,                                                                          \n",
    "    initial_intent_display_name: Optional[str] = None,                                           \n",
    ") -> None:                                                                                       \n",
    "    session_id = session_id if session_id else str(uuid.uuid4())                                                                                                                              \n",
    "    client: CsiClient = CsiClient(config=config, use_secure_channel=config.grpc_cert is not None)      \n",
    "    conversations_service: Conversations = client.services.conversations\n",
    "       \n",
    "    \n",
    "    if \"pyaudio\" in streamer_name:                                                               \n",
    "        # Get audio stream (iterator of audio chunks):                                           \n",
    "        streamer: StreamerInInterface = PyAudioStreamerIn()\n",
    "        \n",
    "        transcription_reqeusts = streamer.create_transciption_requests_from_stream(pipeline_id)\n",
    "        \n",
    "        # Transcribe the stream and get back responses\n",
    "        response_gen: Iterator[speech_to_text_pb2.TranscribeStreamResponse] = \\\n",
    "            s2t_client.services.speech_to_text.transcribe_stream(transcription_reqeusts)\n",
    "              \n",
    "        # Print transcribed utterances\n",
    "        for i, response_chunk in enumerate(response_gen):\n",
    "            print(response_chunk.transcription)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f067bf8a",
   "metadata": {},
   "source": [
    "## T2S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5da6d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "from typing import Any\n",
    "\n",
    "import IPython.display as ipd\n",
    "import soundfile as sf\n",
    "\n",
    "\n",
    "from ondewo.t2s.client.services.text_to_speech import Text2Speech\n",
    "from ondewo.t2s.text_to_speech_pb2 import ListT2sPipelinesRequest, Text2SpeechConfig\n",
    "import IPython.display as ipd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a928594c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_pipeline_by_language_t2s(language,t2s_client):\n",
    "    \n",
    "    pipelines_ids = []\n",
    "    \n",
    "    pipelines = t2s_client.services.text_to_speech.list_t2s_pipelines(\n",
    "        request=ListT2sPipelinesRequest(languages=[language])\n",
    "    ).pipelines\n",
    "    \n",
    "    \n",
    "    for pipeline in pipelines:\n",
    "        pipelines_ids.append(pipeline.id)\n",
    "    \n",
    "    return pipelines_ids\n",
    "\n",
    "def synthesis_request(t2s_service: Text2Speech, **req_kwargs: Any):\n",
    "    request = t2s.SynthesizeRequest(**req_kwargs)\n",
    "    response = t2s_service.synthesize(request=request)\n",
    "\n",
    "    print(\n",
    "        f\"Length of the generated audio is {response.audio_length} sec.\",\n",
    "        f\"Generation time is {response.generation_time} sec.\",\n",
    "    )\n",
    "\n",
    "    bio = io.BytesIO(response.audio)\n",
    "    audio = sf.read(bio)\n",
    "    return audio\n",
    "\n",
    "def say(t2s_client,text, length_scale = 0.9, language = 'de', voice_num = 0):\n",
    "    t2s_service: Text2Speech = t2s_client.services.text_to_speech\n",
    "\n",
    "    t2s_pipeline_id = find_pipeline_by_language_t2s(language,t2s_client)[voice_num]\n",
    "    audio = synthesis_request(\n",
    "    t2s_service, text=text, t2s_pipeline_id=t2s_pipeline_id, length_scale=length_scale\n",
    "    )\n",
    "    \n",
    "    sound = []\n",
    "    sr = audio[1] # sample rate\n",
    "    sound = ipd.Audio(audio[0], rate=sr, autoplay=False) # load a NumPy array\n",
    "\n",
    "    return sound"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd47dc1",
   "metadata": {},
   "source": [
    "## NLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de02b730",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ondewo.nlu.session_pb2 import (\n",
    "    DetectIntentRequest,\n",
    "    DetectIntentResponse,\n",
    "    QueryInput,\n",
    "    QueryParameters,\n",
    "    TextInput,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df814e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_session_nlu(project_id, session_id = None):\n",
    "    session_id = session_id if session_id else str(uuid.uuid4())\n",
    "    project_parent = f'projects/{project_id}/agent'\n",
    "    return f'{project_parent}/sessions/{session_id}'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b92134b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_nlu(session, text=\"Hallo, Ich habe hunger\"):\n",
    "    nlu_response = test_nlu_helper(session,text)\n",
    "    for message in nlu_response.query_result.fulfillment_messages:\n",
    "        print('bot: ', end = '')\n",
    "        print(message.text.text[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9de4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_nlu_helper(session, text):\n",
    "    nlu_request: DetectIntentRequest = DetectIntentRequest(\n",
    "        session=session,\n",
    "        query_input=QueryInput(\n",
    "            text=TextInput(\n",
    "                text= text,\n",
    "                language_code='de',\n",
    "            )\n",
    "        ),\n",
    "    )\n",
    "    # detect intent (= get the NLU response)\n",
    "    nlu_response: DetectIntentResponse = nlu_client.services.sessions.detect_intent(\n",
    "        request=nlu_request,\n",
    "    )\n",
    "    return nlu_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ad1212",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def get_agent_by_id(search_id):\n",
    "    agent_exists(search_id,0)\n",
    "    \n",
    "def get_agent_by_name(search_name):\n",
    "    agent_exists(search_name,1)\n",
    "    \n",
    "def agent_exists(search_agent, search_category):\n",
    "    agents_collect = []\n",
    "    for i in range(0, 100, 10):\n",
    "        agents = nlu_client.services.agents.list_agents(request=agent.ListAgentsRequest(page_token=f'current_index-{i}'))\n",
    "        if agents.agents_with_owners:\n",
    "            agents_collect += [(agent.agent.parent,agent.agent.display_name) for agent in agents.agents_with_owners]\n",
    "    found = 0\n",
    "    for a in agents_collect:\n",
    "        if re.findall(f\"(?i){search_agent}\", a[search_category]):\n",
    "            print(found)\n",
    "            print(a[1])\n",
    "            print(a[0].split('/')[1]) \n",
    "            found += 1 \n",
    "    \n",
    "    if not found :\n",
    "        print(\"Nothing found\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6a88f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nlu_convo():\n",
    "    while True:\n",
    "        text = input('you: ')\n",
    "        if text == 'end convo':\n",
    "            break\n",
    "        test_nlu(session , text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8525ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
